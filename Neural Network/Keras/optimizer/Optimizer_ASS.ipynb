{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c43b7ae-65cf-4aa5-b2e8-b69c7a387e69",
   "metadata": {},
   "source": [
    "#### What is the role of optimization algorithms in artificial neural networksK Why are they necessary?\n",
    "- Ist used to reduce the loss and get the good accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517d5b86-84c1-444c-8b55-4fcf6dfb75fe",
   "metadata": {},
   "source": [
    "#### Explain the concept of gradient descent and its variants. Discuss their differences and tradeoffs in terms of convergence speed and memory requirements?\n",
    "\n",
    "- The basic idea behind gradient descent is to take steps in the direction of the negative gradient of the function at each iteration. The negative gradient points in the direction of steepest descent, which means it guides the algorithm toward the minimum of the function.\n",
    "\n",
    "- In terms of convergence speed, SGD and mini-batch GD often converge faster per iteration compared to BGD since they update the parameters more frequently. Momentum-based methods can further enhance convergence speed by accelerating the learning process in relevant directions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252da769-3dc1-4607-b6f0-f27131b4aa19",
   "metadata": {},
   "source": [
    "#### Describe the challenges associated with traditional gradient descent optimization methods (e.g., slow convergence, local minima. How do modern optimizers address these challenges?\n",
    "- These modern optimization techniques help mitigate the challenges associated with traditional gradient descent methods. They improve convergence speed, increase the likelihood of finding good solutions, and enhance the robustness of optimization algorithms in various problem domains.\n",
    "- Adaptive learning rates : Adaptive learning rate methods, such as AdaGrad, RMSProp, and Adam, adjust the learning rate dynamically during training.\n",
    "- Momentum : \n",
    "- Regularization techniques:L1 and L2 regularization, introduce penalty terms to the loss function to prevent overfitting and improve generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2ab835-8325-47bc-ad01-021a9fa688a7",
   "metadata": {},
   "source": [
    "#### Discuss the concepts of momentum and learning rate in the context of optimization algorithms. How do they impact convergence and model performance\n",
    "- The momentum term allows the optimizer to build up velocity along consistent directions and dampen oscillations along noisy or irrelevant directions.\n",
    "- The learning rate is critical because it balances the convergence speed and the risk of overshooting or oscillating around the optimal solution\n",
    "- momentum and learning rate are essential factors in optimization algorithms. They impact convergence speed, the ability to escape local minima, and the overall performance of the trained model. Properly setting these parameters can lead to faster convergence and improved model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aac6d2-1dcd-45fb-b6cc-07825132bc8b",
   "metadata": {},
   "source": [
    "#### Explain the concept of Stochastic radient Descent (SGD and its advantages compared to traditional gradient descent. Discuss its limitations and scenarios where it is most suitable?\n",
    "\n",
    "- advantages:\n",
    "    - SGD is computationally more efficient than traditional gradient descent methods, especially when dealing with large datasets.\n",
    "    - SGD has lower memory requirements as it only needs to store a single example in memory at a time\n",
    "    - SGD enables continuous learning as it updates the parameters after each example. This allows the model to adapt quickly to changing data patterns or dynamic environments.\n",
    "\n",
    "- Dis advantages:\n",
    "    -  Due to the random sampling of training examples, SGD exhibits more fluctuations in the optimization process compared to traditional gradient descent. \n",
    "    -  SGD may struggle with non-smooth or discontinuous loss functions, as it relies on the gradient information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c142d0-1e0f-4b4f-ac04-1ce738a08f48",
   "metadata": {},
   "source": [
    "####  Describe the concept of Adam optimizer and how it combines momentum and adaptive learning rates. Discuss its benefits and potential drawbacks\n",
    "\n",
    "- Adam (Adaptive Moment Estimation) optimizer is a popular optimization algorithm that combines the concepts of momentum and adaptive learning rates. \n",
    "\n",
    "- Advantages:\n",
    "    - Adam adjusts the learning rate for each parameter individually based on the historical first moment (mean) and second moment (variance) of the gradients. It adapts the learning rate according to the properties of each parameter rather than using a single learning rate for the entire model.\n",
    "    \n",
    "    - Adam does not require excessive memory. It only needs to maintain the moving averages of the first and second moments of the gradients for each parameter.\n",
    "\n",
    "- Disadvantages:\n",
    "    - Although Adam is designed to be less sensitive to learning rate selection, it still requires careful tuning of hyperparameters.\n",
    "    - The adaptive learning rates and additional calculations for estimating moments introduce additional computational overhead compared to simpler optimization algorithms like SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bbecae-fde5-44c8-8e10-88702300ffd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Explain the concept of RMSprop optimizer and how it addresses the challenges of adaptive learning rates. ompare it with Adam and discuss their relative strengths and weaknesses.\n",
    "\n",
    "- Similarities:\n",
    "\n",
    "    - Both RMSprop and Adam are adaptive learning rate optimization algorithms that address the challenges of traditional SGD.\n",
    "    - They both adapt the learning rates based on the historical gradient information of the parameters.\n",
    "    - Both algorithms have mechanisms to mitigate the problems of slow convergence and oscillations.\n",
    "\n",
    "\n",
    "- Differences:\n",
    "\n",
    "    - RMSprop uses only the squared gradients for adapting the learning rates, whereas Adam incorporates both first and second moments of the gradients.\n",
    "    - Adam includes a momentum term that provides an additional \"velocity\" component to the updates, while RMSprop does not explicitly use momentum.\n",
    "    - Adam performs bias correction for the first and second moment estimates, which can be particularly beneficial in the initial stages of training.\n",
    "    - RMSprop has a single learning rate hyperparameter, while Adam has additional hyperparameters for controlling momentum and bias correction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2be583b-b08c-43e2-9687-384ec5bd9d75",
   "metadata": {},
   "source": [
    "##### practical implementation\n",
    "\n",
    "#### Implement SD, Adam, and RMSprop optimizers in a deep learning model using a framework of your choice. Train the model on a suitable dataset and compare their impact on model convergence and performancen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f71f4401-aaf5-48a3-93c3-271e1cfb6d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26467ba7-e3b3-48aa-96f0-0e5b0c126a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd0fe92d-0c67-46ab-927b-3f542853d02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a55d73d5-1494-4d1d-8c43-1909ea8debe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['species']=df['species'].map({'setosa':0,'versicolor':1,'virginica':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b42e987-8101-4aa6-a683-a24b339f07db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7fddea7-9b37-45f3-aebd-422b28cb4f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('species',axis=1)\n",
    "y=df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ef2574c-763d-4872-a1c2-2cddf95d636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c81ee774-54fc-413c-bbaf-56f6f1b5858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52cb9e37-f720-4306-88e9-930c4c379aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>6.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "81            5.5          2.4           3.7          1.0\n",
       "133           6.3          2.8           5.1          1.5\n",
       "137           6.4          3.1           5.5          1.8\n",
       "75            6.6          3.0           4.4          1.4\n",
       "109           7.2          3.6           6.1          2.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bfecbb5-c961-4d55-8d2c-c8c03162ed1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ecb5145-6dc0-4a35-9c38-52e78c1f470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=keras.utils.to_categorical(y_train,num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fab0cd1d-deb9-48a4-8d49-833e5f1ae792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b3b9543-aa94-4e13-ad86-eb3d1eb89373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43775a55-04a8-4d46-9e84-2bd836ccda43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6fe6f7d-c880-4fd4-ac7c-2c5af35d50d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.Sequential([\n",
    "    keras.layers.Dense(100,activation='relu',input_dim=len(X_train.columns)),\n",
    "    keras.layers.Dense(50,activation='relu'),\n",
    "    keras.layers.Dropout(0.02),\n",
    "    keras.layers.Dense(3,activation='softmax')\n",
    "])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a3ad2de-6194-45c2-afa6-3fcaf0bc952b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 - 2s - loss: 1.2400 - accuracy: 0.1918 - val_loss: 1.1079 - val_accuracy: 0.3750 - 2s/epoch - 510ms/step\n",
      "Epoch 2/10\n",
      "3/3 - 0s - loss: 1.0851 - accuracy: 0.3425 - val_loss: 1.0095 - val_accuracy: 0.5938 - 72ms/epoch - 24ms/step\n",
      "Epoch 3/10\n",
      "3/3 - 0s - loss: 0.9842 - accuracy: 0.6575 - val_loss: 0.9348 - val_accuracy: 0.6250 - 81ms/epoch - 27ms/step\n",
      "Epoch 4/10\n",
      "3/3 - 0s - loss: 0.9717 - accuracy: 0.6712 - val_loss: 0.9149 - val_accuracy: 0.9375 - 81ms/epoch - 27ms/step\n",
      "Epoch 5/10\n",
      "3/3 - 0s - loss: 0.9301 - accuracy: 0.7671 - val_loss: 0.8850 - val_accuracy: 0.5938 - 76ms/epoch - 25ms/step\n",
      "Epoch 6/10\n",
      "3/3 - 0s - loss: 0.8751 - accuracy: 0.6849 - val_loss: 0.8638 - val_accuracy: 0.5938 - 77ms/epoch - 26ms/step\n",
      "Epoch 7/10\n",
      "3/3 - 0s - loss: 0.8443 - accuracy: 0.6712 - val_loss: 0.8196 - val_accuracy: 0.9688 - 68ms/epoch - 23ms/step\n",
      "Epoch 8/10\n",
      "3/3 - 0s - loss: 0.8064 - accuracy: 0.9041 - val_loss: 0.7798 - val_accuracy: 0.9375 - 85ms/epoch - 28ms/step\n",
      "Epoch 9/10\n",
      "3/3 - 0s - loss: 0.7850 - accuracy: 0.8630 - val_loss: 0.7569 - val_accuracy: 0.6250 - 79ms/epoch - 26ms/step\n",
      "Epoch 10/10\n",
      "3/3 - 0s - loss: 0.7490 - accuracy: 0.7260 - val_loss: 0.7456 - val_accuracy: 0.5938 - 81ms/epoch - 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x208fc62e5f0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics='accuracy')\n",
    "model.fit(X_train,y_train,batch_size=32,epochs=10,verbose=2,validation_split=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b0fb86b-871a-4be5-8ade-f1d46f8598ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7111111111111111"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_sgd=model.predict(X_test)\n",
    "y_pred_sgd=[np.argmax(i) for i in y_pred_sgd]\n",
    "accuracy_score(y_test,y_pred_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7da85b5f-319b-4373-b672-d3d017608d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 - 2s - loss: 0.7286 - accuracy: 0.6712 - val_loss: 0.6967 - val_accuracy: 1.0000 - 2s/epoch - 596ms/step\n",
      "Epoch 2/10\n",
      "3/3 - 0s - loss: 0.6985 - accuracy: 0.8904 - val_loss: 0.6723 - val_accuracy: 1.0000 - 61ms/epoch - 20ms/step\n",
      "Epoch 3/10\n",
      "3/3 - 0s - loss: 0.6666 - accuracy: 0.8767 - val_loss: 0.6386 - val_accuracy: 1.0000 - 67ms/epoch - 22ms/step\n",
      "Epoch 4/10\n",
      "3/3 - 0s - loss: 0.6125 - accuracy: 0.9041 - val_loss: 0.6030 - val_accuracy: 0.9062 - 67ms/epoch - 22ms/step\n",
      "Epoch 5/10\n",
      "3/3 - 0s - loss: 0.5742 - accuracy: 0.8493 - val_loss: 0.5820 - val_accuracy: 0.6875 - 67ms/epoch - 22ms/step\n",
      "Epoch 6/10\n",
      "3/3 - 0s - loss: 0.5444 - accuracy: 0.7123 - val_loss: 0.5571 - val_accuracy: 0.6875 - 66ms/epoch - 22ms/step\n",
      "Epoch 7/10\n",
      "3/3 - 0s - loss: 0.5095 - accuracy: 0.7808 - val_loss: 0.5214 - val_accuracy: 0.8750 - 64ms/epoch - 21ms/step\n",
      "Epoch 8/10\n",
      "3/3 - 0s - loss: 0.4951 - accuracy: 0.8630 - val_loss: 0.4964 - val_accuracy: 1.0000 - 61ms/epoch - 20ms/step\n",
      "Epoch 9/10\n",
      "3/3 - 0s - loss: 0.4789 - accuracy: 0.9178 - val_loss: 0.4696 - val_accuracy: 1.0000 - 71ms/epoch - 24ms/step\n",
      "Epoch 10/10\n",
      "3/3 - 0s - loss: 0.4273 - accuracy: 0.9726 - val_loss: 0.4483 - val_accuracy: 0.9375 - 61ms/epoch - 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x208fc7687f0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')\n",
    "model.fit(X_train,y_train,batch_size=32,epochs=10,verbose=2,validation_split=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "84c21807-a11e-450d-bee6-ddfc1eec813f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_adam=model.predict(X_test)\n",
    "y_pred_adam=[np.argmax(i) for i in y_pred_adam]\n",
    "accuracy_score(y_test,y_pred_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e311a92-bdae-4166-856a-2ae665f36509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 - 1s - loss: 0.5384 - accuracy: 0.7671 - val_loss: 0.4659 - val_accuracy: 0.6875 - 1s/epoch - 485ms/step\n",
      "Epoch 2/10\n",
      "3/3 - 0s - loss: 0.4413 - accuracy: 0.7397 - val_loss: 0.4076 - val_accuracy: 1.0000 - 65ms/epoch - 22ms/step\n",
      "Epoch 3/10\n",
      "3/3 - 0s - loss: 0.3857 - accuracy: 0.9178 - val_loss: 0.4341 - val_accuracy: 0.8750 - 62ms/epoch - 21ms/step\n",
      "Epoch 4/10\n",
      "3/3 - 0s - loss: 0.3680 - accuracy: 0.9041 - val_loss: 0.3841 - val_accuracy: 1.0000 - 64ms/epoch - 21ms/step\n",
      "Epoch 5/10\n",
      "3/3 - 0s - loss: 0.3742 - accuracy: 0.8904 - val_loss: 0.3712 - val_accuracy: 0.9688 - 67ms/epoch - 22ms/step\n",
      "Epoch 6/10\n",
      "3/3 - 0s - loss: 0.3921 - accuracy: 0.8219 - val_loss: 0.3558 - val_accuracy: 0.9688 - 63ms/epoch - 21ms/step\n",
      "Epoch 7/10\n",
      "3/3 - 0s - loss: 0.3488 - accuracy: 0.8904 - val_loss: 0.4519 - val_accuracy: 0.6562 - 58ms/epoch - 19ms/step\n",
      "Epoch 8/10\n",
      "3/3 - 0s - loss: 0.3931 - accuracy: 0.7945 - val_loss: 0.3391 - val_accuracy: 1.0000 - 59ms/epoch - 20ms/step\n",
      "Epoch 9/10\n",
      "3/3 - 0s - loss: 0.3449 - accuracy: 0.9178 - val_loss: 0.4076 - val_accuracy: 0.7188 - 65ms/epoch - 22ms/step\n",
      "Epoch 10/10\n",
      "3/3 - 0s - loss: 0.3473 - accuracy: 0.8493 - val_loss: 0.3411 - val_accuracy: 0.9688 - 61ms/epoch - 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x208fc76bd60>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='RMSprop',loss='categorical_crossentropy',metrics='accuracy')\n",
    "model.fit(X_train,y_train,batch_size=32,epochs=10,verbose=2,validation_split=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d9eed2a-8051-4093-8166-2f7ac59cbc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000208FC866290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9111111111111111"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_rms=model.predict(X_test)\n",
    "y_pred_rms=[np.argmax(i) for i in y_pred_rms]\n",
    "accuracy_score(y_test,y_pred_rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83981233-bd5b-4de8-9cac-0812d6288f12",
   "metadata": {},
   "source": [
    "## ADAM optimiser is got  high accuracy for iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f9235-1b8c-4c76-b3fd-cc89e2a66c51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
