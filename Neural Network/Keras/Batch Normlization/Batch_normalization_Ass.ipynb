{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d0c7613-33a0-4fef-a917-dd8358aa4e4b",
   "metadata": {},
   "source": [
    "#### Explain the concept of batch normalization in the context of Artificial Neural Networks?\n",
    "- Batch Norm is a normalization technique done between the layers of a Neural Network instead of in the raw data. It is done along mini-batches instead of the full data set. It serves to speed up training and use higher learning rates, making learning easier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0bfdaf-6df7-45b6-9ced-f7f172116a35",
   "metadata": {},
   "source": [
    "#### Describe the benefits of using batch normalization during training?\n",
    "- Using batch normalization allows us to use much higher learning rates, which further increases the speed at which networks train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba99b97-5d05-45f4-b4b6-8a8d7675f626",
   "metadata": {},
   "source": [
    "#### Discuss the working principle of batch normalization, including the normalization step and the learnable parameters.\n",
    "- Two learnable parameters called beta and gamma.\n",
    "- Two non-learnable parameters (Mean Moving Average and Variance Moving Average) are saved as part of the ‘state’ of the Batch Norm layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd9fa86-1747-417f-983c-61636579bfe5",
   "metadata": {},
   "source": [
    "- Choose a dataset of your choice (e.g., MNIST, CIAR-0) and preprocess it\n",
    "- Implement a simple feedforward neural network using any deep learning framework/library (e.g.,\n",
    "Tensorlow, xyTorch)\n",
    "- Train the neural network on the chosen dataset without using batch normalization\n",
    "- Implement batch normalization layers in the neural network and train the model again\n",
    "- Compare the training and validation performance (e.g., accuracy, loss) between the models with and\n",
    "without batch normalization\n",
    "- Discuss the impact of batch normalization on the training process and the performance of the neural\n",
    "network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30b8b690-ecfe-45ae-93a0-d8dcae90ca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43198174-7ce7-4914-9567-e93228319c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "765837f7-ee12-4e78-b606-e1f5f2f35b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_trian),(X_test,y_test)=keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e78463c9-3ecb-451c-b277-1606bc5a684a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dfef304-e346-4906-8c7b-3a53c3a4143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.Sequential([\n",
    "keras.layers.Flatten(input_shape=(28,28)),\n",
    "keras.layers.Dense(200,activation='relu'),\n",
    "keras.layers.Dense(100,activation='relu'),\n",
    "keras.layers.Dense(20,activation='relu'),      \n",
    "keras.layers.Dense(10,activation='softmax')  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18cb8116-ade3-4d39-ae50-32018b3aeaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd092fe0-9650-41d6-8e01-9f65466a7ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 11s 5ms/step - loss: 1.3654 - accuracy: 0.6983\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4833 - accuracy: 0.8855\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2686 - accuracy: 0.9359\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1745 - accuracy: 0.9553\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1224 - accuracy: 0.9668\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1095 - accuracy: 0.9700\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0947 - accuracy: 0.9747\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0800 - accuracy: 0.9785\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0731 - accuracy: 0.9807\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0641 - accuracy: 0.9828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ab3adbc2e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_trian,batch_size=32,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5204a521-2dfa-4438-9f15-6d682147acd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1299 - accuracy: 0.9710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12991714477539062, 0.9710000157356262]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df756a31-6910-4440-8e06-4b39c1dfbe95",
   "metadata": {},
   "source": [
    "## we are getting 97 precent accuracy on without normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8beaf948-e63b-452b-b659-6f19b04589ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode=keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(200,activation='relu'),\n",
    "    keras.layers.Dense(100,activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(20,activation='relu'),\n",
    "    keras.layers.Dense(10,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb1f30af-a862-45d9-aef1-abe7851a16de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18bbf870-41be-459b-a4f8-4c11f7526ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 15s 7ms/step - loss: 0.0674 - accuracy: 0.9827\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0557 - accuracy: 0.9855\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0496 - accuracy: 0.9873\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0543 - accuracy: 0.9866\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0487 - accuracy: 0.9876\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0437 - accuracy: 0.9890\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0473 - accuracy: 0.9883\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0386 - accuracy: 0.9904\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0417 - accuracy: 0.9903\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0411 - accuracy: 0.9901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ab3ada2b50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_trian,epochs=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76ceae8b-55d9-44a4-8356-586a089259f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1382 - accuracy: 0.9769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13822735846042633, 0.9768999814987183]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b40cf-3a0b-4dce-a910-55c17c7522e7",
   "metadata": {},
   "source": [
    "- Accurcay liitle bit incresed\n",
    "- loss is reduced in first epoch compared on without batch normalization\n",
    "- first epichs we got 98 % percent but without normalization 69 %\n",
    "- in 10 th epoch we got 99% accuracy but without normalization we got 98 percent onlu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "655836a6-6018-412a-9d53-94cf9b76a180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1200/1200 [==============================] - 11s 7ms/step - loss: 0.0392 - accuracy: 0.9915\n",
      "Epoch 2/5\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0281 - accuracy: 0.9933\n",
      "Epoch 3/5\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0294 - accuracy: 0.9932\n",
      "Epoch 4/5\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0263 - accuracy: 0.9939\n",
      "Epoch 5/5\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0217 - accuracy: 0.9948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ab3de01cd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode=keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(200,activation='relu'),\n",
    "    keras.layers.Dense(100,activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(20,activation='relu'),\n",
    "    keras.layers.Dense(10,activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "model.fit(X_train,y_trian,epochs=5,batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ac6d2eb-9a0c-4d0a-ab8d-f4dfa3841d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "600/600 [==============================] - 7s 8ms/step - loss: 0.0195 - accuracy: 0.9958\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0153 - accuracy: 0.9966\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.0172 - accuracy: 0.9962\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0217 - accuracy: 0.9958\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0167 - accuracy: 0.9966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ab40571550>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode=keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(200,activation='relu'),\n",
    "    keras.layers.Dense(100,activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(20,activation='relu'),\n",
    "    keras.layers.Dense(10,activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "model.fit(X_train,y_trian,epochs=5,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df1268c2-c394-458e-95b5-d518a641008d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0101 - accuracy: 0.9978\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9986\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.9977\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.9980\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ab418e83a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode=keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(200,activation='relu'),\n",
    "    keras.layers.Dense(100,activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(20,activation='relu'),\n",
    "    keras.layers.Dense(10,activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "model.fit(X_train,y_trian,epochs=5,batch_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bf3f5f-6d71-4b72-8a99-546e72b8a367",
   "metadata": {},
   "source": [
    "##  incresed the batch size our model will get more accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc0b3b5-daca-4ec5-a1b2-7ce7b5376118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c553c998-f27d-4783-8b77-a7fd890e01e8",
   "metadata": {},
   "source": [
    "### Discuss the advantages and potential limitations of batch normalization in improving the training of neural networks.\n",
    "- batch normalization provides significant benefits in terms of improved convergence, faster training, regularization effects, and reduced sensitivity to initialization. However, it also has limitations related to memory usage, mini-batch size, batch order dependency, and compatibility with certain network architectures. Despite these limitations, batch normalization remains a widely used and effective technique for training neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7419bac5-3641-4385-8c7f-7d2480b6cf32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
