{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "627817cc-1c95-42ec-987e-3ac3c864c5d6",
   "metadata": {},
   "source": [
    "#### Q1. What is Gradient Boosting Regression?\n",
    "- Gradient boosting Regression calculates the difference between the current prediction and the known correct target value. This difference is called residual. After that Gradient boosting Regression trains a weak model that maps features to that residual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca6300b-ddd7-47a2-a941-3db69b62f32d",
   "metadata": {},
   "source": [
    "#### Q4. What is a weak learner in Gradient Boosting?\n",
    "- Decision trees are used as the weak learner in gradient boosting. Specifically regression trees are used that output real values for splits and whose output can be added together, allowing subsequent models outputs to be added and “correct” the residuals in the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2759580d-47ac-45fb-87dd-b4cad1fe5369",
   "metadata": {},
   "source": [
    "#### Q5. What is the intuition behind the Gradient Boosting algorithm?\n",
    "- The key idea is to optimize a loss function that measures the difference between the predicted values and the true labels, and to use gradient descent to find the optimal parameters of the model. In gradient boosting, the loss function is typically a differentiable function, such as mean squared error for regression problems or cross-entropy for classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4906a437-350b-4a03-b7ff-a57ac593d153",
   "metadata": {},
   "source": [
    "#### Q6. How does Gradient Boosting algorithm build an ensemble of weak learners?\n",
    "- The Gradient Boosting algorithm builds an ensemble of weak learners by iteratively adding models to the ensemble and adjusting the predictions of each model to correct for the errors of the previous models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba58261-6089-4e32-ab52-f8f36df7b497",
   "metadata": {},
   "source": [
    "### Q7. What are the steps involved in constructing the mathematical intuition of Gradient Boosting algorithm?\n",
    "- Initialize the ensemble\n",
    "- Fit a weak learner\n",
    "- Calculate the residuals\n",
    "- Update the predictions\n",
    "- Repeat steps 2-4\n",
    "- Combine the weak learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2cbdb7-f7e4-4760-a47b-5727b35dd014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
