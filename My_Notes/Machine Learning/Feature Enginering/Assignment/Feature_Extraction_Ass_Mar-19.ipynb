{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a284afd5-7cc6-4ebb-a97a-c83cc3df9590",
   "metadata": {},
   "source": [
    "#### Q1. What is Min-Max scaling, and how is it used in data preprocessing? \n",
    "- Min-Max Scaling, also known as normalization, transforms the data into a range of [0,1] by subtracting the minimum value and dividing by the range. This is useful when the scale of the features varies widely, as it ensures that all features have equal importance in the analysis.\n",
    "#### Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eecb58de-b328-4c32-8f08-2d7d05411b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "df=sns.load_dataset('tips')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98e8843e-ad68-44df-bcab-fabd0dea45c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df1f091f-eb0e-4e56-a118-7d6e43ae7ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.291579</td>\n",
       "      <td>0.001111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.152283</td>\n",
       "      <td>0.073333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.375786</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.431713</td>\n",
       "      <td>0.256667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.450775</td>\n",
       "      <td>0.290000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.291579  0.001111\n",
       "1  0.152283  0.073333\n",
       "2  0.375786  0.277778\n",
       "3  0.431713  0.256667\n",
       "4  0.450775  0.290000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(minmax.fit_transform(df[['total_bill','tip']])).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a8fbb2-3f15-4647-a047-e520d2d06f77",
   "metadata": {},
   "source": [
    "#### Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? Provide an example to illustrate its application.\n",
    "- The unit vector technique, also known as normalization, is a feature scaling method that rescales the features to have a magnitude of one. In other words, it scales the data to fit within a range of -1 to 1.\n",
    "\n",
    "-  Min-Max scaling can be affected by outliers, while the unit vector technique is more robust to outliers since it only considers the magnitude of the data points.\n",
    "\n",
    "- unit vector technique, the relative distances between the data points are preserved, while in Min-Max scaling, the absolute distances are preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0931b976-1585-433d-80a7-120af38e5134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0239bc92-6255-4f1a-ab2e-6ee1951c144e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998238</td>\n",
       "      <td>0.059342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.987357</td>\n",
       "      <td>0.158512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.986407</td>\n",
       "      <td>0.164323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.990372</td>\n",
       "      <td>0.138435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.989395</td>\n",
       "      <td>0.145251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.998238  0.059342\n",
       "1  0.987357  0.158512\n",
       "2  0.986407  0.164323\n",
       "3  0.990372  0.138435\n",
       "4  0.989395  0.145251"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(normalize(df[['total_bill','tip']])).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ccc16d-f628-4430-a27d-5d1a9558af26",
   "metadata": {},
   "source": [
    "#### Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an example to illustrate its application.\n",
    "- PCA (Principal Component Analysis) is a feature extraction technique that transforms data into a lower-dimensional space while preserving the most important information. It does this by finding the principal components, which are the linear combinations of the original features that explain the most variance in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eba4d4e-e26c-401e-83da-653ae2e7647d",
   "metadata": {},
   "source": [
    "#### Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature  Extraction? Provide an example to illustrate this concept.\n",
    "\n",
    "- high-dimensional data is transformed into a lower-dimensional space, while retaining the maximum amount of variance in the original data\n",
    "\n",
    "- PCA can be used for feature extraction by identifying the principal components that are most relevant for the task at hand. These principal components can be used as new features in a machine learning model instead of the original features. This can be particularly useful in situations where the original features are highly correlated or noisy, as PCA can help to remove some of this redundancy and noise.\n",
    "\n",
    "- image recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c915aea9-8834-4e59-9b7f-7abbdc420934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c2c1da3-5dd4-432a-8336-1d2d0694988d",
   "metadata": {},
   "source": [
    "### Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to preprocess the data.\n",
    "- Calculate the minimum and maximum values of each feature (price, rating, delivery time) in the dataset.\n",
    "- For each data point in the dataset, apply the Min-Max scaling formula to rescale the values of each feature to fit within the range of 0 to 1.\n",
    "- Replace the original values of each feature with the rescaled values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78389dcd-fb56-4f1e-9258-a23d5cfb5abb",
   "metadata": {},
   "source": [
    "#### Q6. You are working on a project to build a model to predict stock prices. The dataset contains many features, such as company financial data and market trends. Explain how you would use PCA to reduce the dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49c2bde-fa20-4c1d-b830-ff4958c99ae7",
   "metadata": {},
   "source": [
    "#### Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the values to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7fbdd81-81a6-4d84-a098-fd849d26baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "lstdata=[1, 5, 10, 15, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b35a061a-f962-403e-90b6-a5fb2abbb56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2da786ec-8851-4a1c-9a27-55c659891088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax.fit_transform([lstdata])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f93765-8957-4d11-8709-9b144e446002",
   "metadata": {},
   "source": [
    "#### Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform  Feature Extraction using PCA. How many principal components would you choose to retain, and why?\n",
    "\n",
    "\n",
    "Standardize the data: Before performing PCA, it is important to standardize the data so that all features are on the same scale. This can be done using techniques such as z-score normalization or min-max scaling.\n",
    "\n",
    "Compute the covariance matrix: The covariance matrix can be computed from the standardized data, which represents the relationships between the different features.\n",
    "\n",
    "Compute the eigenvectors and eigenvalues: The eigenvectors and eigenvalues of the covariance matrix can be computed using techniques such as singular value decomposition (SVD) or eigen decomposition.\n",
    "\n",
    "Select the principal components: The principal components can be selected based on the eigenvalues, with higher eigenvalues indicating greater variance in the corresponding eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21933bb1-470e-4169-b1ca-b9fca8d3ef7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
