{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fb64b2b-67ed-4a05-a2cb-f0360e053c94",
   "metadata": {},
   "source": [
    "#### Q1: Define overfitting and underfitting in machine learning. \n",
    "- Over fitting\n",
    "    - train data set occuracy is high and test data accurcay is low \n",
    "    - low bias and high variance\n",
    "- underfitting\n",
    "    - train data set occuracy is low and test data accurcay is low\n",
    "    - high bias and high variance\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d3e2dc-db3a-4cb5-a159-83a5d312512b",
   "metadata": {},
   "source": [
    "#### Q2: How can we reduce overfitting? Explain in brief.\n",
    "-  where a model performs well on the training data but fails to generalize to new data.\n",
    "- Cross-validation: \n",
    "    -Cross-validation involves partitioning the data into training and validation sets and evaluating the model's performance on the validation set. This helps to estimate the model's generalization performance and avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545a2641-aef8-4020-9feb-ece766b04d99",
   "metadata": {},
   "source": [
    "#### Q3: Explain underfitting. List scenarios where underfitting can occur in ML.\n",
    "- The model is not able to learn the relationships between the input features and the target variable, even on the training data.\n",
    "- insufficient training data, over-regularization, poor feature selection, using a simple model architecture, and high bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1cdb1b-b6cb-4206-bb8a-a750e5a3b97a",
   "metadata": {},
   "source": [
    "#### Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and variance, and how do they affect model performance?\n",
    "\n",
    "- The bias-variance tradeoff is a key concept in machine learning that describes the relationship between the bias and variance of a model and its ability to generalize to new data.\n",
    "-The relationship between bias and variance is often depicted as a U-shaped curve, with high bias on one end, high variance on the other end, and a sweet spot in the middle that represents the optimal tradeoff between the two. At the high bias end, the model is too simple and unable to capture the true relationships in the data, resulting in underfitting. At the high variance end, the model is too complex and overfits to the training data, resulting in poor generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac005c6-21c2-43d3-adbb-909ca74a6d36",
   "metadata": {},
   "source": [
    "### Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.How can you determine whether your model is overfitting or underfitting?\n",
    "\n",
    "- overfitting and underfitting is critical for building machine learning models that generalize well to new data. By using techniques such as training and validation curves, cross-validation, residual plots, regularization, and test performance, we can identify whether our model is overfitting or underfitting and take appropriate measures to improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b33f0c-9d58-4ded-98e1-edfbde0cdead",
   "metadata": {},
   "source": [
    "#### Q6: Compare and contrast bias and variance in machine learning. \n",
    "#### What are some examples of high biasand high variance models, and how do they differ in terms of their performance?\n",
    "\n",
    "- The difference between high bias and high variance models, consider the example of fitting a curve to a set of data points. A high bias model would be a linear model that is too simple to capture the true nonlinear relationships in the data, resulting in a poor fit to the data. A high variance model, on the other hand, would be a high-degree polynomial model that overfits to the noise in the data, resulting in a curve that fits the training data very closely but does not generalize well to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e972f40-4f9d-4d4f-aa56-9db8c5bbac41",
   "metadata": {},
   "source": [
    "#### Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe some common regularization techniques and how they work.\n",
    "\n",
    "- Regularization is a technique in machine learning that is used to prevent overfitting of models by adding a penalty term to the loss function. The penalty term is typically a function of the model's parameters, and it is designed to discourage the model from overfitting to the training data by reducing the complexity of the model.\n",
    "\n",
    "L1 regularization (Lasso regularization): This technique adds a penalty term to the loss function that is proportional to the sum of the absolute values of the model's parameters. L1 regularization encourages the model to produce sparse solutions by setting some of the parameters to zero. This can be useful for feature selection or identifying the most important features in the data.\n",
    "\n",
    "L2 regularization (Ridge regularization): This technique adds a penalty term to the loss function that is proportional to the sum of the squares of the model's parameters. L2 regularization encourages the model to produce smooth solutions by shrinking the magnitude of the parameters towards zero. This can be useful for reducing the impact of noisy or irrelevant features in the data.\n",
    "\n",
    "Elastic Net regularization: This technique is a combination of L1 and L2 regularization, and it adds a penalty term to the loss function that is a weighted sum of the L1 and L2 penalty terms. Elastic Net regularization allows for both feature selection and parameter shrinkage, and it can be useful for datasets with high-dimensional feature spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d97db9-8f54-45c8-805d-fc858027abf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
