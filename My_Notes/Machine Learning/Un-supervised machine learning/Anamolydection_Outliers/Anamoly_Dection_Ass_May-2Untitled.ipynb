{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9221ad47-2643-48e3-b8d0-24ff71bf5db9",
   "metadata": {},
   "source": [
    "#### Q1. What is anomaly detection and what is its purpose?\n",
    "- \n",
    "Anomaly detection is a type of machine learning technique that involves identifying data points or patterns that deviate significantly from the expected or normal behavior of a system\n",
    "- The purpose of anomaly detection is to detect and flag unusual or potentially suspicious events, which may indicate the presence of errors, fraud, security threats, or other types of abnormalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb211f7-f27a-4b2c-8ad1-961d8807e88c",
   "metadata": {},
   "source": [
    "#### Q2. What are the key challenges in anomaly detection?\n",
    "- Imbalanced data\n",
    "- Feature engineering : Selecting relevant features or representations that capture the underlying patterns in the data can be challenging, especially in high-dimensional datasets.\n",
    "- False positives: Anomaly detection algorithms may produce false positives, where normal data is classified as anomalous, leading to unnecessary alarms or false accusations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feef519-f416-4b0e-926f-98f04810911d",
   "metadata": {},
   "source": [
    "#### Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?\n",
    "- main difference between unsupervised and supervised anomaly detection is the presence or absence of labeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321e5796-04a1-4036-a4cb-36799ce3e80d",
   "metadata": {},
   "source": [
    "#### Q4. What are the main categories of anomaly detection algorithms?\n",
    "- Machine learning methods: These methods use machine learning algorithms to learn a model of normal behavior from labeled training data, and then use this model to detect anomalies in unlabeled test data.\n",
    "\n",
    "- Clustering-based methods: These methods attempt to identify clusters of similar data points, and then identify data points that are outside of these clusters as anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9a0333-a2fa-4b2a-a945-91eb8ba9a874",
   "metadata": {},
   "source": [
    "### Q5. What are the main assumptions made by distance-based anomaly detection methods?\n",
    "- Distance-based anomaly detection methods assume that anomalies are far from the majority of the data points. These methods typically calculate the distance between each data point and its nearest neighbors or between clusters of data points. Anomalies are identified as points that are located far from other data points or clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32828eb9-2c14-462e-bc09-57c8cc5b94c9",
   "metadata": {},
   "source": [
    "#### Q6. How does the LOF algorithm compute anomaly scores?\n",
    "- The Local Outlier Factor (LOF) algorithm is a density-based algorithm used for detecting outliers or anomalies in a dataset based on local density. The algorithm computes the local density of each data point and compares it to the densities of its neighbours to identify data points that have a significantly lower local density, which are considered outliers.\n",
    "- Data points with LOF scores significantly greater than 1 are considered to be anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546d77e8-94f5-4c59-b404-df6d56d8f0d4",
   "metadata": {},
   "source": [
    "#### Q7. What are the key parameters of the Isolation Forest algorithm?\n",
    "- contamination parameter: It controls the fraction of anomalies in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efed703-ea94-4c1f-889c-77f3da60f187",
   "metadata": {},
   "source": [
    "#### Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the anomaly score for a data point that has an average path length of 5.0 compared to the average path length of the trees?\n",
    "\n",
    "anomaly score = 2^(-average path length / c)\n",
    "\n",
    "where c is a normalization factor that depends on the number of data points in the dataset and the number of trees in the forest. It is given by:\n",
    "\n",
    "c = (2 * H(n-1)) / n\n",
    "\n",
    "where n is the number of data points and H(i) is the i-th harmonic number.\n",
    "\n",
    "For a dataset of 3000 data points and 100 trees, we have:\n",
    "\n",
    "n = 3000\n",
    "H(n-1) = H(2999) = 8.4943\n",
    "\n",
    "So, the normalization factor is:\n",
    "\n",
    "c = (2 * H(2999)) / 3000 = 0.005663\n",
    "\n",
    "Plugging in the values, we get:\n",
    "\n",
    "anomaly score = 2^(-5.0/0.005663) = 0.000084"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dc0964-d429-4d35-8887-9a90a99cb0ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
