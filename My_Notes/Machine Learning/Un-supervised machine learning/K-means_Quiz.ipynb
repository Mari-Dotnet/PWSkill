{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bd17a8e-f8da-4d1b-aa86-6fbf5b91ced7",
   "metadata": {},
   "source": [
    "#### What is the main difference between supervised and unsupervised learning?\n",
    "- Supervised learning requires labeled data, while unsupervised learning does not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35be04-a1ea-4a4d-994f-1443d9fdf484",
   "metadata": {},
   "source": [
    "#### What is the main difference between hierarchical clustering and k-means clustering?\n",
    "-  Hierarchical clustering can handle any number of clusters, while k-means clustering requires a predefined number of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7531a27-0c0e-47d0-a77a-c8d93315e83f",
   "metadata": {},
   "source": [
    "#### What is the difference between agglomerative and divisive hierarchical clustering?\n",
    "- Agglomerative clustering forms clusters by recursively combining the data, while divisive clustering forms clusters by recursively dividing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd28bc17-341d-4def-8c2a-a9a6370a6331",
   "metadata": {},
   "source": [
    "#### What is the main advantage of k-means clustering compared to hierarchical clustering?\n",
    "- K-means clustering is faster and more scalable than hierarchical clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95996559-f0f3-4ca7-9ecc-51c8ff431ea3",
   "metadata": {},
   "source": [
    "#### What is the elbow method used for in k-means clustering?\n",
    "- To determine the optimal number of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9277f8d8-5332-4608-8ccd-82aafab2bf4c",
   "metadata": {},
   "source": [
    "#### Which of the following is an example of a distance metric used in clustering?\n",
    "- Euclidean distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0956cd2f-1dd1-42c2-9a80-91c5c1a0b1dd",
   "metadata": {},
   "source": [
    "#### Which of the following is true about agglomerative clustering?\n",
    "- It can be used with any type of distance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4576dce0-3a15-4df6-a785-28e40ca75e0c",
   "metadata": {},
   "source": [
    "#### Which of the following statements best describes hierarchical clustering?\n",
    "- Hierarchical clustering is a method for constructing a tree-like structure of clusters, where each node in the tree represents a cluster of data points. The tree can be visualised as a dendrogram, where the branches represent the distance between clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d411e1-3cad-4f86-987f-d3c3cdccf7c3",
   "metadata": {},
   "source": [
    "#### Which of the following is a key difference between agglomerative and divisive hierarchical clustering?\n",
    "- Agglomerative clustering is a bottom-up approach, while divisive clustering is a top-down approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b2a76e-4309-4328-8d4f-6e7900aae362",
   "metadata": {},
   "source": [
    "#### Which of the following methods is commonly used to measure the distance between clusters in hierarchical clustering?\n",
    "- Euclidean distance\n",
    "- Manhattan distance\n",
    "- Mahalanobis distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93c218a-45ba-4bfa-a62d-5bcced068ab8",
   "metadata": {},
   "source": [
    "####  In hierarchical clustering, which of the following is true about the linkage criterion?\n",
    "- It determines how clusters are combined at each step of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3d0a02-756d-4a21-bc0f-f04314fac7eb",
   "metadata": {},
   "source": [
    "#### Which of the following linkage criteria tends to produce compact, spherical clusters?\n",
    "-  Ward's linkage tends to produce compact, spherical clusters because it minimizes the variance within each cluster when deciding how to merge clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab621a9f-2d56-4290-9232-e5f0676530f6",
   "metadata": {},
   "source": [
    "#### Agglomerative hierarchical clustering, which of the following is true about the merging process?\n",
    "-  In agglomerative hierarchical clustering, the merging process starts with each data point in its own cluster, and at each iteration, the two closest clusters are merged together until all data points belong to a single cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5718f31a-6d6e-4935-81e6-857ef963e80a",
   "metadata": {},
   "source": [
    "####  Which of the following is a measure of how well-defined clusters are?\n",
    "- The Silhouette Coefficient measures how well-defined clusters are by computing the mean distance between a data point and all other points in its cluster, as well as the mean distance between the same point and all other points in the nearest neighboring cluster. A score close to 1 indicates well-defined clusters, while a score close to -1 indicates poorly defined clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2598b8b2-5e34-4fbb-96eb-4ab8d75227a1",
   "metadata": {},
   "source": [
    "#### Which of the following is a measure of how pure clusters are with respect to a given ground truth?\n",
    "- Homogeneity measures how pure clusters are with respect to a given ground truth, by computing the conditional entropy of the cluster labels given the true labels. A score close to 1 indicates highly homogeneous clusters, while a score close to 0 indicates low homogeneity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e3db2c-898e-4a8e-bf34-f9fbe17156e5",
   "metadata": {},
   "source": [
    "#### Which of the following is a measure of how well all data points are assigned to clusters, with respect to a given ground truth?\n",
    "- Completeness measures how well all data points are assigned to clusters, with respect to a given ground truth, by computing the conditional entropy of the true labels given the cluster labels. A score close to 1 indicates highly complete clustering, while a score close to 0 indicates incomplete clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275f0edc-546a-4162-9f1b-a0d8bfc521d7",
   "metadata": {},
   "source": [
    "#### Which of the following is an unsupervised evaluation metric for clustering?\n",
    "- Silhouette Coefficient. The Silhouette Coefficient is an unsupervised evaluation metric for clustering, as it does not rely on any external ground truth labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03223f52-2eef-462e-a5f6-7b7d5ae65e34",
   "metadata": {},
   "source": [
    "#### Which of the following measures both the homogeneity and completeness of a clustering with respect to a given ground truth?\n",
    "-  V-Measure combines homogeneity and completeness into a single score by computing their harmonic mean, weighted by the number of samples in each cluster. A score close to 1 indicates highly accurate clustering, while a score close to 0 indicates inaccurate clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f52613e-c8a9-4a99-b17d-ff19c371d251",
   "metadata": {},
   "source": [
    "#### Which of the following evaluation metrics penalizes clustering that split a ground truth cluster into multiple clusters?\n",
    "- Homogeneity. Homogeneity penalizes clustering that split a ground truth cluster into multiple clusters, as this would result in a higher conditional entropy of the cluster labels given the true labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c52d549-23ac-47e8-8059-4e9bd04b3f43",
   "metadata": {},
   "source": [
    "#### Which of the following evaluation metrics penalizes clustering that merge multiple ground truth clusters into a single cluster?\n",
    "- Completeness penalizes clustering that merge multiple ground truth clusters into a single cluster, as this would result in a higher conditional entropy of the true labels given the cluster labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c99b0d-258f-49ac-a6a9-3d08b7b05b21",
   "metadata": {},
   "source": [
    "#### Cosine similarity is a measure of\n",
    "- Similarity between two points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb8675d-5e4c-46f7-ad2d-cc36ff45f670",
   "metadata": {},
   "source": [
    "#### Cosine similarity is commonly used in\n",
    "- Both Natural Language Processing and Image Processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5371b29d-45e7-4829-aac4-0b234d150aa3",
   "metadata": {},
   "source": [
    "#### What is the range of the cosine similarity score?\n",
    "- [-1, 1]. The cosine similarity score ranges from -1 (perfectly dissimilar) to 1 (perfectly similar)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f280e92d-d7fa-4b30-8f91-cde0b330329c",
   "metadata": {},
   "source": [
    "#### Silhouette score is a measure of\n",
    "- Both distance between a point and its cluster centre, and distance between a point and the nearest neighbouring cluster centre. The Silhouette score is a measure of how well-defined clusters are, by computing the mean distance between a data point and all other points in its cluster (A), as well as the mean distance between the same point and all other points in the nearest neighboring cluster (B). A score close to 1 indicates well-defined clusters, while a score close to -1 indicates poorly defined clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abd52a0-ac5b-4c0a-9fcb-8e102546de35",
   "metadata": {},
   "source": [
    "#### The mathematical intuition behind the Silhouette score is:\n",
    "- Cohesion and Separation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dde4665-34f3-43b4-a348-30b0f5a89a61",
   "metadata": {},
   "source": [
    "#### A Silhouette score close to 0 indicates:\n",
    "- A Silhouette score close to 0 indicates that the data points are very close to the decision boundary between two clusters, making it difficult to determine which cluster they should belong to. This is not indicative of well-defined or poorly defined clusters, or an optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ac916f-d04b-4c8c-8b72-caeecb3c897b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
